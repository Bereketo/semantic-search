{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["### Installing Required Libraries\n","We need to install `transformers`, `datasets`, and `sentence-transformers` along with FAISS-GPU. The following commands ensure that everything is set up.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T19:51:04.017892Z","iopub.status.busy":"2024-09-04T19:51:04.017514Z","iopub.status.idle":"2024-09-04T19:51:42.422642Z","shell.execute_reply":"2024-09-04T19:51:42.421389Z","shell.execute_reply.started":"2024-09-04T19:51:04.017858Z"},"trusted":true},"outputs":[],"source":["!pip install transformers datasets sentence-transformers\n","!pip install faiss-gpu\n","!pip install faiss-cpu\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T19:51:56.696983Z","iopub.status.busy":"2024-09-04T19:51:56.695995Z","iopub.status.idle":"2024-09-04T19:52:09.729124Z","shell.execute_reply":"2024-09-04T19:52:09.727916Z","shell.execute_reply.started":"2024-09-04T19:51:56.696928Z"},"trusted":true},"outputs":[],"source":["!pip install streamlit"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loading and Preprocessing\n","We'll start by loading the IMDb dataset and then preprocessing it to extract the relevant information. We will also generate sentence embeddings for the movie overviews using the `SentenceTransformer`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-09-04T20:15:28.392030Z","iopub.status.busy":"2024-09-04T20:15:28.391590Z","iopub.status.idle":"2024-09-04T20:15:28.435749Z","shell.execute_reply":"2024-09-04T20:15:28.434973Z","shell.execute_reply.started":"2024-09-04T20:15:28.391988Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","import numpy as np\n","\n","data_path = \"/kaggle/input/imdb-dataset-of-top-1000-movies-and-tv-shows/imdb_top_1000.csv\"\n","\n","def load_data(data_path):\n","    \"\"\"Load data from csv\"\"\"\n","    df = pd.read_csv(data_path)\n","    return df\n","\n","def preprocess_data(df):\n","    \"\"\"Select relevant columns and preprocess the text\"\"\"\n","    df_selected = df[\n","        [\n","            \"Series_Title\",\n","            \"Genre\",\n","            \"Overview\",\n","            \"Director\",\n","            \"Star1\",\n","            \"Star2\",\n","            \"Star3\",\n","            \"Star4\",\n","        ]\n","    ]\n","    return df_selected\n","\n","\n","\n","\n","df = load_data(data_path)\n","df_selected = preprocess_data(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T21:11:42.132981Z","iopub.status.busy":"2024-09-04T21:11:42.132069Z","iopub.status.idle":"2024-09-04T21:11:42.165620Z","shell.execute_reply":"2024-09-04T21:11:42.164636Z","shell.execute_reply.started":"2024-09-04T21:11:42.132940Z"},"trusted":true},"outputs":[],"source":["def build_faiss_index(embeddings):\n","    \"\"\"Build and return faiss IVF index\"\"\"\n","    dimensions = embeddings[0].shape[0]\n","    nlist = 30\n","    quantizer = faiss.IndexFlatL2(dimensions)\n","    index = faiss.IndexIVFFlat(quantizer, dimensions, nlist, faiss.METRIC_L2)\n","\n","    embeddings_array = np.array(embeddings.tolist())\n","\n","    assert not index.is_trained\n","    index.train(embeddings_array)\n","    assert index.is_trained\n","\n","    index.add(embeddings_array)\n","    return index\n","index = build_faiss_index(df_selected[\"Overview_Embeddings\"])"]},{"cell_type":"markdown","metadata":{},"source":["### Preparing RAG Data and FAISS Index\n","This step involves converting the preprocessed data into a format suitable for RAG and saving it, along with creating and saving a FAISS index of the embeddings.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:15:33.727484Z","iopub.status.busy":"2024-09-04T20:15:33.727065Z","iopub.status.idle":"2024-09-04T20:16:10.047353Z","shell.execute_reply":"2024-09-04T20:16:10.046398Z","shell.execute_reply.started":"2024-09-04T20:15:33.727443Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset\n","import faiss\n","\n","\n","dataset_path = \"/kaggle/working/rag_dataset\"\n","index_path = \"/kaggle/working/rag_index/faiss_index\"\n","\n","\n","def generate_embeddings(df, model_name=\"all-mpnet-base-v2\"):\n","    \"\"\"Generate embeddings using SentenceTransformer model.\"\"\"\n","    model = SentenceTransformer(model_name)\n","    df[\"Overview_Embeddings\"] = df[\"Overview\"].apply(\n","        lambda x: model.encode(x).astype(np.float32)\n","    )\n","    return df, model\n","\n","\n","def prepare_rag_data(df, dataset_path, index_path):\n","    \"\"\"Prepare RAG data by saving it to disk.\"\"\"\n","    df[\"Overview_Embeddings\"] = df[\"Overview_Embeddings\"].apply(\n","        lambda x: np.array(x, dtype=np.float32)\n","    )\n","\n","    \n","    df_rag = df.rename(columns={\"Series_Title\": \"title\", \"Overview\": \"text\"})\n","    df_rag[\"embeddings\"] = df[\"Overview_Embeddings\"]\n","\n","    rag_dataset = Dataset.from_pandas(df_rag[[\"title\", \"text\", \"embeddings\"]])\n","\n","   \n","    rag_dataset.save_to_disk(dataset_path)\n","\n","    rag_dataset.add_faiss_index(column=\"embeddings\", index_name=\"embeddings\")\n","    rag_dataset.get_index(\"embeddings\").save(index_path)\n","\n","    return rag_dataset\n","\n","\n","df, model = generate_embeddings(df_selected)\n","rag_dataset = prepare_rag_data(df, dataset_path, index_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Initializing the RAG Model\n","We'll now initialize the RAG model, using the FAISS index and dataset we prepared. This model will be used for retrieval-augmented generation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:16:57.360243Z","iopub.status.busy":"2024-09-04T20:16:57.359411Z","iopub.status.idle":"2024-09-04T20:17:10.760297Z","shell.execute_reply":"2024-09-04T20:17:10.759443Z","shell.execute_reply.started":"2024-09-04T20:16:57.360199Z"},"trusted":true},"outputs":[],"source":["from datasets import load_from_disk\n","from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n","import faiss\n","\n","def initialize_rag_model():\n","    dataset_path = \"/kaggle/working/rag_dataset\"\n","    index_path = \"/kaggle/working/rag_index/faiss_index\"\n","\n","    dataset = load_from_disk(dataset_path)\n","    dataset.load_faiss_index(\"embeddings\", index_path)\n","\n","    rag_tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n","    rag_retriever = RagRetriever.from_pretrained(\n","        \"facebook/rag-token-nq\",\n","        index_name=\"embeddings\",\n","        indexed_dataset=dataset,\n","    )\n","    rag_model = RagTokenForGeneration.from_pretrained(\n","        \"facebook/rag-token-nq\", retriever=rag_retriever\n","    )\n","    \n","    return rag_tokenizer, rag_retriever, rag_model\n","\n","rag_tokenizer, rag_retriever, rag_model = initialize_rag_model()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Implementing the Search Functionality\n","Finally, we implement the search functionality. This enables users to input a query and get a list of similar movies, either by using FAISS or by refining the results with RAG.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T22:04:03.365428Z","iopub.status.busy":"2024-09-04T22:04:03.364456Z","iopub.status.idle":"2024-09-04T22:04:03.599191Z","shell.execute_reply":"2024-09-04T22:04:03.597902Z","shell.execute_reply.started":"2024-09-04T22:04:03.365382Z"},"trusted":true},"outputs":[],"source":["def search_query(\n","    query,\n","    model,\n","    index,\n","    df,\n","    k=5,\n","    nprobe=10,\n","    use_rag=False,\n","    rag_model=None,\n","    rag_tokenizer=None,\n","):\n","    \"\"\"Search for the most similar items\"\"\"\n","\n","    if use_rag and rag_model and rag_tokenizer:\n","        input_ids = rag_tokenizer(query, return_tensors=\"pt\")[\"input_ids\"]\n","        generated_ids = np.array([df_selected])\n","        generated_ids = np.array(generated_ids)  # Convert the list to a numpy array\n","        rag_response = rag_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n","        \n","        question_hidden_states = rag_model.question_encoder(input_ids=input_ids).last_hidden_state\n","        query_embedding = rag_model.retriever(question_hidden_states, input_ids, return_tensors=\"pt\").embedding.detach().cpu().numpy()[0]\n","    else:\n","        \n","        query_embedding = model.encode(query)\n","\n","    query_embedding = np.array([query_embedding])\n","    index.nprobe = nprobe\n","    distances, indices = index.search(query_embedding, k)\n","\n","    results = df.iloc[indices[0]]\n","    return results, rag_response if use_rag else None\n","\n","\n","query = \"A story about hope and friendship.\"\n","use_rag = True  \n","\n","results, rag_response = search_query(query, model, index, df_selected, use_rag=use_rag, rag_model=rag_model, rag_tokenizer=rag_tokenizer)\n","\n","\n","print(\"Top results:\")\n","for idx, row in results.iterrows():\n","    print(f\"Title: {row['Series_Title']}\")\n","    print(f\"Overview: {row['Overview']}\")\n","    print(\"---\")\n","\n","if rag_response:\n","    print(\"RAG response:\")\n","    print(rag_response)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Run the app with streamlit (Optional)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:49:34.156963Z","iopub.status.busy":"2024-09-04T20:49:34.156244Z","iopub.status.idle":"2024-09-04T20:49:34.165300Z","shell.execute_reply":"2024-09-04T20:49:34.164236Z","shell.execute_reply.started":"2024-09-04T20:49:34.156908Z"},"trusted":true},"outputs":[],"source":["\n","app_code = \"\"\"\n","import streamlit as st\n","\n","data_path = \"/kaggle/input/imdb-dataset-of-top-1000-movies-and-tv-shows/imdb_top_1000.csv\"\n","dataset_path = \"/kaggle/working/rag_dataset\"\n","index_path = \"/kaggle/working/rag_index/faiss_index\"\n","\n","\n","@st.cache_data\n","def load_and_prepare_data():\n","    df = load_data(data_path)\n","    df_selected = preprocess_data(df)\n","    df_selected, model = generate_embeddings(df_selected)\n","    index = build_faiss_index(df_selected[\"Overview_Embeddings\"])\n","\n","    prepare_rag_data(df_selected, dataset_path, index_path)\n","    rag_tokenizer, rag_retriever, rag_model = initialize_rag_model()\n","\n","    return df_selected, model, index, rag_tokenizer, rag_model\n","\n","\n","df_selected, model, index, rag_tokenizer, rag_model = load_and_prepare_data()\n","\n","st.title(\"Movie Search App with RAG\")\n","\n","st.write(\"Enter a movie description or plot to find similar movies:\")\n","\n","query = st.text_input(\"Search query\", \"\")\n","\n","use_rag = st.checkbox(\"Use RAG to refine search\")\n","\n","if query:\n","    st.write(\"Searching for movies similar to your query...\")\n","    results, rag_response = search_query(\n","        query,\n","        model,\n","        index,\n","        df_selected,\n","        use_rag=use_rag,\n","        rag_model=rag_model,\n","        rag_tokenizer=rag_tokenizer,\n","    )\n","\n","    if use_rag and rag_response:\n","        st.write(\"Refined response from RAG:\")\n","        st.write(rag_response)\n","\n","    st.write(f\"Top {len(results)} results:\")\n","\n","    for idx, row in results.iterrows():\n","        st.subheader(row[\"Series_Title\"])\n","        st.write(f\"**Genre:** {row['Genre']}\")\n","        st.write(f\"**Director:** {row['Director']}\")\n","        st.write(f\"**Overview:** {row['Overview']}\")\n","        st.write(\n","            f\"**Stars:** {row['Star1']}, {row['Star2']}, {row['Star3']}, {row['Star4']}\"\n","        )\n","        st.write(\"---\")\n","\n","if st.checkbox(\"Show dataset\"):\n","    st.write(df_selected.head(10))\n","\"\"\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:19:48.261343Z","iopub.status.busy":"2024-09-04T20:19:48.260861Z","iopub.status.idle":"2024-09-04T20:19:48.274248Z","shell.execute_reply":"2024-09-04T20:19:48.273329Z","shell.execute_reply.started":"2024-09-04T20:19:48.261295Z"},"trusted":true},"outputs":[],"source":["\n","with open('/kaggle/working/app.py', 'w') as f:\n","    f.write(app_code)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:19:48.275666Z","iopub.status.busy":"2024-09-04T20:19:48.275372Z","iopub.status.idle":"2024-09-04T20:19:49.349549Z","shell.execute_reply":"2024-09-04T20:19:49.348421Z","shell.execute_reply.started":"2024-09-04T20:19:48.275635Z"},"trusted":true},"outputs":[],"source":["!curl ipv4.icanhazip.com"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:20:10.937125Z","iopub.status.busy":"2024-09-04T20:20:10.936236Z","iopub.status.idle":"2024-09-04T20:49:34.144079Z","shell.execute_reply":"2024-09-04T20:49:34.142710Z","shell.execute_reply.started":"2024-09-04T20:20:10.937080Z"},"trusted":true},"outputs":[],"source":["\n","!streamlit run /kaggle/working/app.py &>./logs.txt & npx localtunnel --port 8501"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1131493,"sourceId":1898721,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
